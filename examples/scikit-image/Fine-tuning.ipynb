{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# efetuar download do dataset previamente: https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "\n",
    "import os\n",
    "\n",
    "WEIGHTS_DIR = './weights'\n",
    "ORIGINAL_TRAIN_DIR = os.path.join('./data', 'train')\n",
    "REDUCED_TRAIN_DIR = os.path.join('./data', 'train_reduced')\n",
    "REDUCED_VAL_DIR = os.path.join('./data', 'val_reduced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "makedirs() got an unexpected keyword argument 'exist_ok'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cc746df876eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEIGHTS_DIR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mN_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1250\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: makedirs() got an unexpected keyword argument 'exist_ok'"
     ]
    }
   ],
   "source": [
    "# Data preparation\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
    "\n",
    "N_train = 1250\n",
    "N_val = 125\n",
    "\n",
    "print (os.path.isdir(REDUCED_TRAIN_DIR))\n",
    "\n",
    "# Remove \"not\" if not executed yet\n",
    "if not os.path.isdir(REDUCED_TRAIN_DIR):\n",
    "    for cls in ('cat', 'dog'):\n",
    "        dst_train_dir = os.path.join(REDUCED_TRAIN_DIR, cls)\n",
    "        dst_val_dir = os.path.join(REDUCED_VAL_DIR, cls)\n",
    "        os.makedirs(dst_train_dir, exist_ok=True)\n",
    "        os.makedirs(dst_val_dir, exist_ok=True)\n",
    "        files = glob.glob(os.path.join(ORIGINAL_TRAIN_DIR, cls + '*'))\n",
    "        random.shuffle(files)\n",
    "        for f in files[:N_train]:\n",
    "            shutil.copy(f, dst_train_dir)\n",
    "        for f in files[N_train:N_train + N_val]:\n",
    "            shutil.copy(f, dst_val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.3\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "# Rede usada de 16 camadas.\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importando a rede e usando o peso da imagenet, include_top=False não será incluido o topo da rede.\n",
    "base_model = VGG16(weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x) # (x) concatena camapadas\n",
    "# Adicionando uma rede densa, uma nova camada.\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# Add a binary classification layer (sigmoid)\n",
    "# camada de classificação\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1025      \n",
      "=================================================================\n",
      "Total params: 15,241,025\n",
      "Trainable params: 15,241,025\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1 False\n",
      "1 block1_conv1 True\n",
      "2 block1_conv2 True\n",
      "3 block1_pool True\n",
      "4 block2_conv1 True\n",
      "5 block2_conv2 True\n",
      "6 block2_pool True\n",
      "7 block3_conv1 True\n",
      "8 block3_conv2 True\n",
      "9 block3_conv3 True\n",
      "10 block3_pool True\n",
      "11 block4_conv1 True\n",
      "12 block4_conv2 True\n",
      "13 block4_conv3 True\n",
      "14 block4_pool True\n",
      "15 block5_conv1 True\n",
      "16 block5_conv2 True\n",
      "17 block5_conv3 True\n",
      "18 block5_pool True\n",
      "19 global_average_pooling2d_1 True\n",
      "20 dense_1 True\n",
      "21 dense_2 True\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name, layer.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:11]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2500 images belonging to 2 classes.\n",
      "Found 250 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "height, width = 224, 224\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=45.,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='reflect',\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        REDUCED_TRAIN_DIR,\n",
    "        target_size=(height, width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "        REDUCED_VAL_DIR,\n",
    "        target_size=(height, width),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/keras/engine/training.py:953: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 9/78 [==>...........................] - ETA: 3:51:09 - loss: 1.4056 - acc: 0.4757"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "tb_callback = TensorBoard(log_dir='tb_log')\n",
    "\n",
    "training = model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=train_generator.samples // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_generator.samples // batch_size,\n",
    "        callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('trained_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Inferência em uma imagem\n",
    "from keras.preprocessing import image\n",
    "from skimage.io import imshow\n",
    "import numpy as np\n",
    "\n",
    "img = image.load_img('data/train/dog.100.jpg', target_size=(224, 224))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = model.predict(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
