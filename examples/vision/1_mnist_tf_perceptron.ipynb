{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# The data will be downloaded\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Cached the data into MNIST_data folder.\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_10:0\", shape=(?, 784), dtype=float32)\n",
      "Tensor(\"Placeholder_11:0\", shape=(?, 10), dtype=float32)\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# Defining placeholders for input data and targets\n",
    "input_size = 784\n",
    "no_classes = 10\n",
    "batch_size = 100\n",
    "total_batches = 200\n",
    "\n",
    "# None indicates that it can be of any size\n",
    "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])\n",
    "\n",
    "print x_input\n",
    "print y_input\n",
    "\n",
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable_2:0' shape=(784, 10) dtype=float32_ref>\n",
      "<tf.Variable 'Variable_3:0' shape=(10,) dtype=float32_ref>\n",
      "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# Defining the variables for a fully connected layer (camada totalmente conectada)\n",
    "weights = tf.Variable(tf.random_normal([input_size, no_classes]))\n",
    "bias = tf.Variable(tf.random_normal([no_classes]))\n",
    "\n",
    "print weights\n",
    "print bias\n",
    "\n",
    "# The logits produced by the perceptron has to be compared against one-hot labels y_input\n",
    "logits = tf.matmul(x_input, weights) + bias\n",
    "\n",
    "print logits\n",
    "\n",
    "# A perda pode ser calculada pela média das entropias cruzadas.\n",
    "\n",
    "# Then the cross-entropy is fed through gradient descent optimization done \n",
    "# Em seguida, a entropia cruzada é alimentada pela otimização de descida de gradiente feita pelo \n",
    "# tf.train.GradientDescentOptimizer.\n",
    "\n",
    "# O otimizador leva a perda e minimiza com uma taxa de aprendizado de 0,5. \n",
    "# O cálculo do softmax, entropia cruzada, perda, otimização é mostrado a seguir:\n",
    "\n",
    "# The softmax and cross-entropies are computed together from the tf.nn package\n",
    "softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_input, logits=logits)\n",
    "loss_operation = tf.reduce_mean(softmax_cross_entropy)\n",
    "\n",
    "optimiser = tf.train.GradientDescentOptimizer(learning_rate=0.5).minimize(loss_operation)\n",
    "\n",
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "# Start the session and initialize the variables using a global variable initializer:\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0481\n",
      "11.0137\n",
      "11.2552\n",
      "10.0036\n",
      "8.20578\n",
      "9.1967\n",
      "7.37702\n",
      "7.51785\n",
      "7.02469\n",
      "6.90343\n",
      "5.52854\n",
      "6.58713\n",
      "4.85031\n",
      "5.96119\n",
      "5.68443\n",
      "3.96349\n",
      "4.87225\n",
      "4.75698\n",
      "4.2639\n",
      "3.87784\n",
      "4.05891\n",
      "4.27771\n",
      "3.71205\n",
      "4.07346\n",
      "3.63746\n",
      "3.29405\n",
      "3.44072\n",
      "3.67497\n",
      "3.1485\n",
      "2.7856\n",
      "3.64805\n",
      "2.06697\n",
      "2.84106\n",
      "2.33486\n",
      "2.79137\n",
      "2.71484\n",
      "2.31798\n",
      "2.67277\n",
      "2.58044\n",
      "1.97553\n",
      "1.99547\n",
      "2.27951\n",
      "1.88907\n",
      "2.58973\n",
      "2.56133\n",
      "2.96796\n",
      "1.91328\n",
      "1.454\n",
      "1.44311\n",
      "2.94522\n",
      "1.79195\n",
      "2.13319\n",
      "2.09824\n",
      "1.91563\n",
      "2.0699\n",
      "2.1607\n",
      "1.85198\n",
      "1.9537\n",
      "1.6466\n",
      "1.85429\n",
      "1.7956\n",
      "1.66319\n",
      "1.94837\n",
      "2.28936\n",
      "2.01025\n",
      "2.41084\n",
      "2.20242\n",
      "1.74606\n",
      "1.83111\n",
      "1.89823\n",
      "1.72428\n",
      "1.69602\n",
      "2.2165\n",
      "1.49693\n",
      "2.13795\n",
      "1.98578\n",
      "1.91776\n",
      "2.07093\n",
      "1.60013\n",
      "1.27634\n",
      "1.65717\n",
      "1.16228\n",
      "1.01978\n",
      "2.04593\n",
      "1.83329\n",
      "2.03095\n",
      "2.22886\n",
      "1.72564\n",
      "1.17687\n",
      "1.51038\n",
      "1.35136\n",
      "1.23773\n",
      "1.63592\n",
      "1.86304\n",
      "1.20219\n",
      "1.76832\n",
      "1.40069\n",
      "1.59657\n",
      "1.2129\n",
      "1.12962\n",
      "1.20828\n",
      "1.42059\n",
      "1.53908\n",
      "1.53435\n",
      "1.04748\n",
      "1.40488\n",
      "1.17706\n",
      "1.59208\n",
      "1.02566\n",
      "1.15605\n",
      "1.25691\n",
      "1.67402\n",
      "1.61422\n",
      "1.32027\n",
      "1.34385\n",
      "1.35008\n",
      "1.0489\n",
      "1.52701\n",
      "1.22467\n",
      "1.24742\n",
      "1.1071\n",
      "1.85625\n",
      "1.367\n",
      "1.14419\n",
      "1.32656\n",
      "1.08949\n",
      "1.09183\n",
      "0.988704\n",
      "1.07383\n",
      "0.885312\n",
      "1.06478\n",
      "1.33584\n",
      "1.66854\n",
      "0.914228\n",
      "1.35373\n",
      "0.963435\n",
      "1.51646\n",
      "1.11401\n",
      "1.01\n",
      "1.06151\n",
      "1.23455\n",
      "1.49004\n",
      "1.11418\n",
      "1.383\n",
      "0.723194\n",
      "1.64883\n",
      "1.13128\n",
      "1.52921\n",
      "0.77051\n",
      "1.13293\n",
      "1.24696\n",
      "1.31862\n",
      "0.812311\n",
      "1.09985\n",
      "1.05419\n",
      "1.12274\n",
      "1.49073\n",
      "1.02342\n",
      "1.26851\n",
      "0.990676\n",
      "1.2882\n",
      "1.31299\n",
      "0.738843\n",
      "1.2021\n",
      "1.00182\n",
      "0.947853\n",
      "1.26313\n",
      "0.950371\n",
      "1.10232\n",
      "1.29811\n",
      "1.16894\n",
      "1.50958\n",
      "1.12824\n",
      "1.52081\n",
      "1.31871\n",
      "0.709056\n",
      "0.729432\n",
      "0.989462\n",
      "1.29666\n",
      "1.03622\n",
      "0.860656\n",
      "0.964597\n",
      "0.726173\n",
      "1.00448\n",
      "1.12115\n",
      "0.67381\n",
      "0.985934\n",
      "0.944075\n",
      "1.06425\n",
      "1.08981\n",
      "0.953546\n",
      "0.761205\n",
      "1.22652\n",
      "1.36081\n",
      "1.2666\n",
      "1.18846\n",
      "1.30625\n",
      "1.26864\n",
      "0.961368\n",
      "0.53775\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "# Training the model is carried out by running the session with the required tensors. \n",
    "# The optimizer has to be called in order for the graph to update the weights:\n",
    "\n",
    "# Treinar o modelo é realizado executando a sessão com os tensores necessários.\n",
    "# O otimizador deve ser chamado para que o gráfico atualize os pesos:\n",
    "for batch_no in range(total_batches):\n",
    "    mnist_batch = mnist_data.train.next_batch(batch_size)\n",
    "    _, loss_value = session.run([optimiser, loss_operation], feed_dict={\n",
    "        x_input: mnist_batch[0],\n",
    "        y_input: mnist_batch[1]\n",
    "    })\n",
    "    # The loss is expected to decrease as we are minimizing the loss.\n",
    "    print(loss_value)\n",
    "\n",
    "print 'finish'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A previsão deve ser o índice da ativação máxima. Deve ser comparado com a verdade básica nos rótulos MNIST para previsões corretas. A precisão é calculada usando a média das previsões corretas. A precisão dos dados pode ser avaliada executando a sessão com dados de teste como o dicionário de feeds. Quando todo o programa é executado, ele deve finalmente produzir uma precisão de cerca de 90%. A definição do modelo pode parecer muito explícita sem APIs mais simples para treinamento e teste. Este nível de definição básica dá o poder da expressividade do TensorFlow. Nas próximas seções, veremos APIs de nível superior. A precisão obtida pelo perceptron não é grande, e na próxima seção, usaremos uma rede mais profunda com camadas de convolução para melhorar a precisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy : ', 0.81029999)\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "predictions = tf.argmax(logits, 1)\n",
    "correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "\n",
    "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
    "accuracy_value = session.run(accuracy_operation, feed_dict={\n",
    "    x_input: test_images, \n",
    "    y_input: test_labels\n",
    "})\n",
    "print('Accuracy : ', accuracy_value)\n",
    "session.close()\n",
    "print 'finish'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
