{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "import numpy as np\n",
    "from keras.utils import np_utils\n",
    "import tensorflow as tf\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def mcor(y_true, y_pred):\n",
    "    #matthews_correlation\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X has shape (num_rows, num_cols), where the training data are stored as row vectors\n",
    "# X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "# y must have an output vector for each input vector\n",
    "# y = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "# Set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "X = np.array([[0,0],[0,1],[1,0],[1,1]]).astype('float32')\n",
    "y = np.array([[0],[1],[1],[0]]).astype('float32')\n",
    "\n",
    "# One-hot encoding the output\n",
    "y = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential model\n",
    "model = Sequential()\n",
    "# 1st Layer - Add an input layer of 32 nodes with the same input shape as\n",
    "# the training samples in X\n",
    "# Keras requires the input shape to be specified in the first layer\n",
    "model.add(Dense(32, input_dim=2))\n",
    "# 2nd Layer - Add a fully connected output layer\n",
    "model.add(Activation(\"sigmoid\"))\n",
    "model.add(Dense(2))\n",
    "# Add a sigmoid activation layer\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# teste = Sequential()\n",
    "# teste.add(Dense(32, input_dim=2))\n",
    "# teste.add(Activation(\"sigmoid\"))\n",
    "# teste.add(Dense(2))\n",
    "# teste.add(Activation(\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "RMSprop = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "Adagrad = optimizers.Adagrad(lr=0.01, epsilon=None, decay=0.0)\n",
    "Adadelta = optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "Adam = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "Adamax = optimizers.Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n",
    "Nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "\n",
    "# model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "# model.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "# binary_crossentropy      -> 0.88888895511627197\n",
    "# categorical_crossentropy -> 0.88888895511627197\n",
    "# mean_squared_error       -> 0.88888895511627197\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer= \"adam\", metrics=[mcor, recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=RMSprop, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adagrad, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adadelta, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adamax, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Nadam, metrics=[mcor,recall, f1, 'accuracy'])\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics = ['accuracy'])\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=RMSprop, metrics = ['accuracy'])\n",
    "# model.compile(loss=\"mean_squared_error\", optimizer=sgd, metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x125b01950>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 193ms/step\n",
      "('Accuracy: ', 0.75)\n",
      "('Loss: ', 0.125)\n",
      "('mcor: ', 0.77459663152694702)\n",
      "('recall: ', 1.0)\n",
      "('f1: ', 0.88888895511627197)\n",
      "\n",
      "Predictions:\n",
      "[[  9.99999881e-01   7.62263355e-08]\n",
      " [  1.00000000e+00   1.00000000e+00]\n",
      " [  8.89055656e-08   9.99999881e-01]\n",
      " [  1.00000000e+00   5.92950862e-08]]\n"
     ]
    }
   ],
   "source": [
    "# Scoring the model\n",
    "score = model.evaluate(X, y)\n",
    "print(\"Accuracy: \", score[-1])\n",
    "print(\"Loss: \", score[0])\n",
    "print(\"mcor: \", score[1])\n",
    "print(\"recall: \", score[2])\n",
    "print(\"f1: \", score[3])\n",
    "\n",
    "# Checking the predictions\n",
    "print(\"\\nPredictions:\")\n",
    "print(model.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
